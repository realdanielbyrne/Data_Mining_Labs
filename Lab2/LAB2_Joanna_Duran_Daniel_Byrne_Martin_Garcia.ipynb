{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Two: Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will build upon the predictive analysis (classification) that we completed in the\n",
    "previous mini-project, adding additional modeling from new classification algorithms as well as\n",
    "more explanations that are inline with the CRISP-DM framework.\n",
    "\n",
    "We chose to continue to use the CIFAR-10 dataset. We identified the two tasks from the dataset to classify. \n",
    "Task 1: Cats and dogs\n",
    "Task 2: Birds and airplanes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By Martin Garcia, Joanna Duran, Daniel Byrne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "import sklearn.naive_bayes as b\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.utils import compute_class_weight\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (5.0, 4.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Minilab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Understanding\n",
    "Our objective was to create a logistic regression model and a support vector machine model for the classification of each image. We were to determine which model is best suited for this standard classification task based on a comparison on their prediction accuracy, training times, and computational efficiency.\n",
    "\n",
    "The CIFAR-10 dataset (Canadian Institute For Advanced Research) is a collection of images that are commonly used to train machine learning and computer vision algorithms. It is one of the most widely used datasets for machine learning research. It is a subset of the 80 million tiny images dataset and consists of 60,000 32x32 color images containing one of 10 object classes, with 6,000 images per class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Meaning Type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The CIFAR-10 dataset\n",
    "We are using the [CIFAR-10](http://www.cs.toronto.edu/~kriz/cifar.html) dataset which consists of 60,000 32x32 colour images in 10 classes, with 6,000 images per class. The dataset includes are 50,000(80%) training images and 10,000(20%) test images broken in to 5 pre-randomized training batches and 1 test batch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each training batch contains 10,000 observations with a row vector of length 3,072 representative of color image of 32x32 pixels. The first 1,024 columns consist of red values, followed by green, and blue. The data also incorporates labels ranging from 0 to 9 and are listed below.\n",
    "\n",
    "* airplane : 0\n",
    "* automobile : 1\n",
    "* bird : 2\n",
    "* cat : 3\n",
    "* deer : 4\n",
    "* dog : 5\n",
    "* frog : 6\n",
    "* horse : 7\n",
    "* ship : 8\n",
    "* truck : 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test batch contains 1,000 randomly-selected images from each class. The 5 training batches are randomized and contain a variable number of images from each class. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classes are completely mutually exclusive. There is no overlap between automobiles and trucks. \"Automobile\" includes sedans, SUVs, things of that sort. \"Truck\" includes only big trucks. Neither includes pickup trucks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data, reshape to 32x32 matrix per color, transpose matrices\n",
    "def load_cfar10_batch(path, batch_id = None, reshape = True):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "    path -- path the datasets\n",
    "    batch_id -- id of the batch (1 to 5) to load\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- python dictionary containing:\n",
    "                    X -- features\n",
    "                    Y -- labels\n",
    "    \"\"\"\n",
    "    if batch_id is not None:\n",
    "        filepath = path + 'data_batch_' + str(batch_id)\n",
    "    else:\n",
    "        filepath = path\n",
    "        \n",
    "    with open(filepath, mode='rb') as file:\n",
    "        # note the encoding type is 'latin1'\n",
    "        batch = pickle.load(file, encoding='latin1')\n",
    "    \n",
    "    if reshape:    \n",
    "        X = batch['data'].reshape((len(batch['data']), 3, 32, 32)).transpose(0, 2, 3, 1)\n",
    "        Y = np.array(batch['labels'])\n",
    "    else:\n",
    "        X = batch['data']\n",
    "        Y = np.array(batch['labels'])\n",
    "        \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cfar10_dataset():\n",
    "    \"\"\"\n",
    "    Loads the cfar10 dataset\n",
    "    \n",
    "    Arguments: \n",
    "        None\n",
    "    \n",
    "    Returns:\n",
    "        X - Training dataset\n",
    "        Y - Training labels\n",
    "         - Test datset\n",
    "        y_test - test labelss\n",
    "    \"\"\"\n",
    "    x_test,y_test = load_cfar10_batch(\"data/test_batch\",None,False)\n",
    "    X,Y = load_cfar10_batch(\"data/\",1,False)\n",
    "\n",
    "    for n in range(2,6):\n",
    "        x,y = load_cfar10_batch(\"data/\",n,False)    \n",
    "        X = np.concatenate((X,x),axis=0)\n",
    "        Y = np.concatenate((Y,y),axis=0)\n",
    "\n",
    "\n",
    "    return (X,Y,x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch #3:\n",
      "# of Samples: 10000\n",
      "\n",
      "Label Counts of [0](AIRPLANE) : 994\n",
      "Label Counts of [1](AUTOMOBILE) : 1042\n",
      "Label Counts of [2](BIRD) : 965\n",
      "Label Counts of [3](CAT) : 997\n",
      "Label Counts of [4](DEER) : 990\n",
      "Label Counts of [5](DOG) : 1029\n",
      "Label Counts of [6](FROG) : 978\n",
      "Label Counts of [7](HORSE) : 1015\n",
      "Label Counts of [8](SHIP) : 961\n",
      "Label Counts of [9](TRUCK) : 1029\n",
      "\n",
      "Example of Image 7101:\n",
      "Image - Min Value: 0 Max Value: 230\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 1 Name: automobile\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#load labels for our label\n",
    "def load_label_names():\n",
    "    return ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "#display images\n",
    "def display_stats(data, batch_id, sample_id):\n",
    "    features, labels = load_cfar10_batch(data, batch_id)\n",
    "\n",
    "    if not (0 <= sample_id < len(features)):\n",
    "        print('{} samples in batch {}.  {} is out of range.'.format(len(features), batch_id, sample_id))\n",
    "        return None\n",
    "\n",
    "    print('\\nStats of batch #{}:'.format(batch_id))\n",
    "    print('# of Samples: {}\\n'.format(len(features)))\n",
    "\n",
    "    label_names = load_label_names()\n",
    "    label_counts = dict(zip(*np.unique(labels, return_counts=True)))\n",
    "    for key, value in label_counts.items():\n",
    "        print('Label Counts of [{}]({}) : {}'.format(key, label_names[key].upper(), value))\n",
    "\n",
    "    sample_image = features[sample_id]\n",
    "    sample_label = labels[sample_id]\n",
    "\n",
    "    print('\\nExample of Image {}:'.format(sample_id))\n",
    "    print('Image - Min Value: {} Max Value: {}'.format(sample_image.min(), sample_image.max()))\n",
    "    print('Image - Shape: {}'.format(sample_image.shape))\n",
    "    print('Label - Label Id: {} Name: {}'.format(sample_label, label_names[sample_label]))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(sample_image)\n",
    "\n",
    "batch_id = random.randint(1,5)\n",
    "sample_id = random.randint(1,10000)\n",
    "display_stats( \"data/\", batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will define and prepare our class variables. \n",
    "\n",
    "Each of the batch files contains a dictionary with the following elements: \n",
    "\n",
    "data -- a 10000x3072 numpy array of uint8s. Each row of the array stores a 32x32 colour image. The first 1024 entries contain the red channel values, the next 1024 the green, and the final 1024 the blue. The image is stored in row-major order, so that the first 32 entries of the array are the red channel values of the first row of the image. \n",
    "\n",
    "labels -- a list of 10000 numbers in the range 0-9. The number at index i indicates the label of the ith image in the array data.\n",
    "\n",
    "The dataset contains another file, called batches.meta. It too contains a Python dictionary object. It has the following entries: \n",
    "\n",
    "label_names -- a 10-element list which gives meaningful names to the numeric labels in the labels array described above. For example, label_names[0] == \"airplane\", label_names[1] == \"automobile\", etc.\n",
    "\n",
    "\"Define and prepare your class variables. Use proper variable representations (int, float, one-hot, etc.). Use pre-processing methods (as needed) for dimensionality reduction, scaling, etc. Remove variables that are not needed/useful for the analysis.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify_labels(df,indexes,val = 10):\n",
    "    \"\"\"\n",
    "    Return a modified label dataset filtered ot use only the classes specified\n",
    "\n",
    "    Arguments:\n",
    "    indees: indexes to filter\n",
    "    df : label dataset\n",
    "    val: new label value\n",
    "\n",
    "    Returns:\n",
    "    fdf - filtered df\n",
    "      \n",
    "    \"\"\"\n",
    "\n",
    "    def f(n):\n",
    "        if n in indexes:\n",
    "            return n\n",
    "        else:\n",
    "            return val\n",
    "    \n",
    "    return list(map(f,df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data\n",
    "X,Y,x_test,y_test = load_cfar10_dataset()\n",
    "\n",
    "# Simplify datasets to the classes we care about\n",
    "Ycatdog = simplify_labels(Y,[3,5],10)\n",
    "y_test_catdog =simplify_labels(y_test,[3,5],10)\n",
    "Ybirdplane = simplify_labels(Y,[0,2],10)\n",
    "y_test_birdplane = simplify_labels(y_test,[0,2],10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final training dataset is identical to the original.  However, we've created 4 new label datasets\n",
    "\n",
    "- Ycatdog, y_test_catdog  : Cat and dog labels are retained, all others forced to next unused label\n",
    "- Ybirdplane,y_test_birdplane : Bird and plane  labels are retained, all others forced to next unused label\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling and Evaluation 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Choose and explain your evaluation metrics that you will use (i.e., accuracy,\n",
    "precision, recall, F-measure, or any metric we have discussed). Why are the measure(s) appropriate for analyzing the results of your modeling? Give a detailed explanation backing up any assertions.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildmodel(nmodel,X,Y,x_test,y_test,**modelargs):\n",
    "    \"\"\"\n",
    "    Builds one of a subset of sklearn models and returns a score\n",
    "    \n",
    "    Arguments:\n",
    "    modeltype -- One of either \"multi\", \"gauss\", \"bernoulli\", \"c\", \"nn\" \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    if nmodel == 'multi':\n",
    "        m = b.MultinomialNB(**modelargs)\n",
    "    elif nmodel == 'gauss':\n",
    "        m = b.GaussianNB(**modelargs)\n",
    "    elif nmodel == 'bernoulli':\n",
    "        m = b.BernoulliNB(**modelargs)\n",
    "    elif nmodel == \"mlp\":\n",
    "        m = MLPClassifier(**modelargs)\n",
    "    elif nmodel == \"svm\":\n",
    "        m = SGDClassifier(**modelargs)\n",
    "    m.fit(X, Y)\n",
    "    score = m.score(x_test,y_test) * 100\n",
    "\n",
    "    return m,score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB score :% 54.28\n"
     ]
    }
   ],
   "source": [
    "multiNB,multiNBScore = buildmodel('multi',X,Ycatdog,x_test,y_test_catdog, alpha = .01)\n",
    "print(\"MultinomialNB score :%\",round(multiNBScore,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB score :% 54.31\n"
     ]
    }
   ],
   "source": [
    "gaussNB, gaussNBScore = buildmodel('gauss',X,Ycatdog,x_test,y_test_catdog,priors=None, var_smoothing=1e-09)\n",
    "print(\"GaussianNB score :%\",round(gaussNBScore,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB score :% 77.17\n"
     ]
    }
   ],
   "source": [
    "berboulliNB, bernoulliNBScore = buildmodel('bernoulli',X,Ycatdog,x_test,y_test_catdog,alpha = .01)\n",
    "print(\"BernoulliNB score :%\",round(bernoulliNBScore,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp, mlpScore = buildmodel('mlp',X,Ycatdog,x_test,y_test_catdog,\n",
    "                           activation = 'relu',hidden_layer_sizes=(10,),learning_rate ='adaptive',verbose = True)\n",
    "print(\"Multi-layer Perceptron score :%\",round(mlpScore,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 20294.11, NNZs: 3072, Bias: -84.645561, T: 50000, Avg. loss: 3470215.398533\n",
      "Total training time: 0.24 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 12778.59, NNZs: 3072, Bias: -96.358249, T: 100000, Avg. loss: 612957.079097\n",
      "Total training time: 0.48 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 10215.61, NNZs: 3072, Bias: -102.802831, T: 150000, Avg. loss: 359173.699296\n",
      "Total training time: 0.73 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 8471.62, NNZs: 3072, Bias: -106.666573, T: 200000, Avg. loss: 254891.946326\n",
      "Total training time: 0.99 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 7589.39, NNZs: 3072, Bias: -109.910705, T: 250000, Avg. loss: 199003.490681\n",
      "Total training time: 1.24 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 6945.58, NNZs: 3072, Bias: -112.158257, T: 300000, Avg. loss: 160347.617879\n",
      "Total training time: 1.48 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 6364.49, NNZs: 3072, Bias: -113.420424, T: 350000, Avg. loss: 136193.964157\n",
      "Total training time: 1.73 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 5932.29, NNZs: 3072, Bias: -115.797845, T: 400000, Avg. loss: 118242.214371\n",
      "Total training time: 1.99 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 5577.39, NNZs: 3072, Bias: -117.797253, T: 450000, Avg. loss: 104119.304099\n",
      "Total training time: 2.24 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 5230.74, NNZs: 3072, Bias: -119.133530, T: 500000, Avg. loss: 93184.123797\n",
      "Total training time: 2.49 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 5006.95, NNZs: 3072, Bias: -120.451176, T: 550000, Avg. loss: 85219.728147\n",
      "Total training time: 2.76 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 4814.19, NNZs: 3072, Bias: -122.010901, T: 600000, Avg. loss: 76341.337042\n",
      "Total training time: 3.06 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 4622.33, NNZs: 3072, Bias: -123.403729, T: 650000, Avg. loss: 70351.057799\n",
      "Total training time: 3.34 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 4401.59, NNZs: 3072, Bias: -124.512176, T: 700000, Avg. loss: 65892.431582\n",
      "Total training time: 3.60 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 4283.03, NNZs: 3072, Bias: -125.396487, T: 750000, Avg. loss: 60637.595619\n",
      "Total training time: 3.88 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 4146.81, NNZs: 3072, Bias: -126.243010, T: 800000, Avg. loss: 56692.689959\n",
      "Total training time: 4.18 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 4014.94, NNZs: 3072, Bias: -127.013183, T: 850000, Avg. loss: 53578.366818\n",
      "Total training time: 4.44 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 3897.31, NNZs: 3072, Bias: -127.748179, T: 900000, Avg. loss: 50460.165788\n",
      "Total training time: 4.70 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 3794.15, NNZs: 3072, Bias: -128.317631, T: 950000, Avg. loss: 47651.764777\n",
      "Total training time: 4.97 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 3695.32, NNZs: 3072, Bias: -129.015902, T: 1000000, Avg. loss: 45124.190787\n",
      "Total training time: 5.22 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 3635.85, NNZs: 3072, Bias: -129.898367, T: 1050000, Avg. loss: 42709.061409\n",
      "Total training time: 5.47 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 3550.35, NNZs: 3072, Bias: -130.789344, T: 1100000, Avg. loss: 40924.648731\n",
      "Total training time: 5.71 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 3474.04, NNZs: 3072, Bias: -131.712519, T: 1150000, Avg. loss: 39187.841802\n",
      "Total training time: 5.97 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 3399.71, NNZs: 3072, Bias: -132.249316, T: 1200000, Avg. loss: 37496.111244\n",
      "Total training time: 6.22 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 3337.44, NNZs: 3072, Bias: -132.739711, T: 1250000, Avg. loss: 35583.375740\n",
      "Total training time: 6.46 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 3263.76, NNZs: 3072, Bias: -133.183648, T: 1300000, Avg. loss: 34103.023157\n",
      "Total training time: 6.70 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 3202.72, NNZs: 3072, Bias: -133.795138, T: 1350000, Avg. loss: 33087.986485\n",
      "Total training time: 6.95 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 3144.75, NNZs: 3072, Bias: -134.250452, T: 1400000, Avg. loss: 31896.190614\n",
      "Total training time: 7.20 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 3085.71, NNZs: 3072, Bias: -134.692138, T: 1450000, Avg. loss: 30799.511256\n",
      "Total training time: 7.46 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 3042.72, NNZs: 3072, Bias: -135.248897, T: 1500000, Avg. loss: 29601.691789\n",
      "Total training time: 7.72 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 2994.67, NNZs: 3072, Bias: -135.741366, T: 1550000, Avg. loss: 28898.712418\n",
      "Total training time: 8.04 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 2947.28, NNZs: 3072, Bias: -136.240814, T: 1600000, Avg. loss: 27920.796609\n",
      "Total training time: 8.36 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 2909.91, NNZs: 3072, Bias: -136.542560, T: 1650000, Avg. loss: 27268.345349\n",
      "Total training time: 8.63 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 2866.08, NNZs: 3072, Bias: -136.971642, T: 1700000, Avg. loss: 26079.057325\n",
      "Total training time: 8.91 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 2818.50, NNZs: 3072, Bias: -137.446033, T: 1750000, Avg. loss: 25260.589643\n",
      "Total training time: 9.18 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 2774.88, NNZs: 3072, Bias: -137.858271, T: 1800000, Avg. loss: 24895.304322\n",
      "Total training time: 9.44 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 2731.11, NNZs: 3072, Bias: -138.260142, T: 1850000, Avg. loss: 24071.775102\n",
      "Total training time: 9.70 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 2696.27, NNZs: 3072, Bias: -138.680696, T: 1900000, Avg. loss: 23243.254212\n",
      "Total training time: 9.97 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 2669.73, NNZs: 3072, Bias: -139.090093, T: 1950000, Avg. loss: 22575.578863\n",
      "Total training time: 10.22 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 2636.39, NNZs: 3072, Bias: -139.474680, T: 2000000, Avg. loss: 22116.005488\n",
      "Total training time: 10.46 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 2599.03, NNZs: 3072, Bias: -139.893338, T: 2050000, Avg. loss: 21631.579042\n",
      "Total training time: 10.71 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 2570.65, NNZs: 3072, Bias: -140.281707, T: 2100000, Avg. loss: 21096.681214\n",
      "Total training time: 10.97 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 2535.77, NNZs: 3072, Bias: -140.691714, T: 2150000, Avg. loss: 20718.484734\n",
      "Total training time: 11.21 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 2515.36, NNZs: 3072, Bias: -141.004656, T: 2200000, Avg. loss: 19717.263836\n",
      "Total training time: 11.45 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 2489.46, NNZs: 3072, Bias: -141.404601, T: 2250000, Avg. loss: 19473.091993\n",
      "Total training time: 11.70 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 2461.16, NNZs: 3072, Bias: -141.764181, T: 2300000, Avg. loss: 19211.097933\n",
      "Total training time: 11.97 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 2435.59, NNZs: 3072, Bias: -142.008180, T: 2350000, Avg. loss: 18684.407708\n",
      "Total training time: 12.24 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 2407.30, NNZs: 3072, Bias: -142.378269, T: 2400000, Avg. loss: 18322.841886\n",
      "Total training time: 12.53 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 2380.09, NNZs: 3072, Bias: -142.699019, T: 2450000, Avg. loss: 17921.509492\n",
      "Total training time: 13.07 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 2351.53, NNZs: 3072, Bias: -143.021476, T: 2500000, Avg. loss: 17566.690258\n",
      "Total training time: 13.42 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 2327.05, NNZs: 3072, Bias: -143.263655, T: 2550000, Avg. loss: 17371.215793\n",
      "Total training time: 13.77 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 2301.56, NNZs: 3072, Bias: -143.586634, T: 2600000, Avg. loss: 16819.086902\n",
      "Total training time: 14.14 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 2282.14, NNZs: 3072, Bias: -143.822113, T: 2650000, Avg. loss: 16846.099982\n",
      "Total training time: 14.46 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 2257.74, NNZs: 3072, Bias: -144.176669, T: 2700000, Avg. loss: 16287.382296\n",
      "Total training time: 14.78 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 2234.17, NNZs: 3072, Bias: -144.477339, T: 2750000, Avg. loss: 15943.911246\n",
      "Total training time: 15.12 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 2220.14, NNZs: 3072, Bias: -144.686841, T: 2800000, Avg. loss: 15904.311536\n",
      "Total training time: 15.48 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 2205.55, NNZs: 3072, Bias: -144.991053, T: 2850000, Avg. loss: 15375.632755\n",
      "Total training time: 15.87 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 2183.98, NNZs: 3072, Bias: -145.387228, T: 2900000, Avg. loss: 15118.603351\n",
      "Total training time: 16.23 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 2165.84, NNZs: 3072, Bias: -145.684371, T: 2950000, Avg. loss: 14860.951027\n",
      "Total training time: 16.52 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 2149.91, NNZs: 3072, Bias: -145.892667, T: 3000000, Avg. loss: 14772.881744\n",
      "Total training time: 16.80 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 2129.24, NNZs: 3072, Bias: -146.117530, T: 3050000, Avg. loss: 14450.801970\n",
      "Total training time: 17.08 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 2115.52, NNZs: 3072, Bias: -146.370967, T: 3100000, Avg. loss: 14178.195097\n",
      "Total training time: 17.34 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 2097.23, NNZs: 3072, Bias: -146.585176, T: 3150000, Avg. loss: 14032.677490\n",
      "Total training time: 17.60 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 2082.33, NNZs: 3072, Bias: -146.821111, T: 3200000, Avg. loss: 13728.929544\n",
      "Total training time: 17.88 seconds.\n",
      "-- Epoch 65\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 2067.84, NNZs: 3072, Bias: -147.047277, T: 3250000, Avg. loss: 13376.621810\n",
      "Total training time: 18.16 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 2051.10, NNZs: 3072, Bias: -147.203373, T: 3300000, Avg. loss: 13284.615567\n",
      "Total training time: 18.42 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 2035.35, NNZs: 3072, Bias: -147.461903, T: 3350000, Avg. loss: 13011.721667\n",
      "Total training time: 18.67 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 2019.40, NNZs: 3072, Bias: -147.615542, T: 3400000, Avg. loss: 12923.825816\n",
      "Total training time: 18.92 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 2006.56, NNZs: 3072, Bias: -147.831725, T: 3450000, Avg. loss: 12693.036440\n",
      "Total training time: 19.18 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 1989.18, NNZs: 3072, Bias: -148.009820, T: 3500000, Avg. loss: 12482.405179\n",
      "Total training time: 19.42 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 1974.43, NNZs: 3072, Bias: -148.256243, T: 3550000, Avg. loss: 12426.648489\n",
      "Total training time: 19.66 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 1960.81, NNZs: 3072, Bias: -148.463248, T: 3600000, Avg. loss: 12194.223827\n",
      "Total training time: 19.91 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 1947.52, NNZs: 3072, Bias: -148.672752, T: 3650000, Avg. loss: 11958.631148\n",
      "Total training time: 20.15 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 1936.27, NNZs: 3072, Bias: -148.784102, T: 3700000, Avg. loss: 11840.585335\n",
      "Total training time: 20.39 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 1925.20, NNZs: 3072, Bias: -148.926111, T: 3750000, Avg. loss: 11582.311459\n",
      "Total training time: 20.63 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 1910.81, NNZs: 3072, Bias: -149.167376, T: 3800000, Avg. loss: 11547.583151\n",
      "Total training time: 20.88 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 1897.40, NNZs: 3072, Bias: -149.363411, T: 3850000, Avg. loss: 11212.089271\n",
      "Total training time: 21.15 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 1885.27, NNZs: 3072, Bias: -149.574852, T: 3900000, Avg. loss: 11130.780690\n",
      "Total training time: 21.40 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 1876.07, NNZs: 3072, Bias: -149.773875, T: 3950000, Avg. loss: 10972.440015\n",
      "Total training time: 21.65 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 1867.87, NNZs: 3072, Bias: -149.937592, T: 4000000, Avg. loss: 10933.641193\n",
      "Total training time: 21.92 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 1854.60, NNZs: 3072, Bias: -150.158416, T: 4050000, Avg. loss: 10882.875787\n",
      "Total training time: 22.17 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 1843.47, NNZs: 3072, Bias: -150.291126, T: 4100000, Avg. loss: 10641.611522\n",
      "Total training time: 22.42 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 1832.42, NNZs: 3072, Bias: -150.516638, T: 4150000, Avg. loss: 10457.198549\n",
      "Total training time: 22.67 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 1822.92, NNZs: 3072, Bias: -150.739029, T: 4200000, Avg. loss: 10381.475027\n",
      "Total training time: 22.93 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 1810.99, NNZs: 3072, Bias: -150.890493, T: 4250000, Avg. loss: 10342.530350\n",
      "Total training time: 23.19 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 1794.86, NNZs: 3072, Bias: -151.070644, T: 4300000, Avg. loss: 10219.822519\n",
      "Total training time: 23.45 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 1785.93, NNZs: 3072, Bias: -151.204729, T: 4350000, Avg. loss: 9968.248883\n",
      "Total training time: 23.70 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 1778.59, NNZs: 3072, Bias: -151.351084, T: 4400000, Avg. loss: 9831.389090\n",
      "Total training time: 23.97 seconds.\n",
      "-- Epoch 89\n",
      "Norm: 1767.75, NNZs: 3072, Bias: -151.500304, T: 4450000, Avg. loss: 9836.086353\n",
      "Total training time: 24.23 seconds.\n",
      "-- Epoch 90\n",
      "Norm: 1759.14, NNZs: 3072, Bias: -151.699083, T: 4500000, Avg. loss: 9686.967447\n",
      "Total training time: 24.49 seconds.\n",
      "-- Epoch 91\n",
      "Norm: 1748.98, NNZs: 3072, Bias: -151.889260, T: 4550000, Avg. loss: 9607.634488\n",
      "Total training time: 24.74 seconds.\n",
      "-- Epoch 92\n",
      "Norm: 1740.50, NNZs: 3072, Bias: -152.035527, T: 4600000, Avg. loss: 9450.660497\n",
      "Total training time: 25.01 seconds.\n",
      "-- Epoch 93\n",
      "Norm: 1731.90, NNZs: 3072, Bias: -152.139132, T: 4650000, Avg. loss: 9367.663489\n",
      "Total training time: 25.27 seconds.\n",
      "-- Epoch 94\n",
      "Norm: 1722.88, NNZs: 3072, Bias: -152.310178, T: 4700000, Avg. loss: 9284.484506\n",
      "Total training time: 25.52 seconds.\n",
      "-- Epoch 95\n",
      "Norm: 1713.91, NNZs: 3072, Bias: -152.437300, T: 4750000, Avg. loss: 9147.440821\n",
      "Total training time: 25.77 seconds.\n",
      "-- Epoch 96\n",
      "Norm: 1705.69, NNZs: 3072, Bias: -152.625549, T: 4800000, Avg. loss: 9079.738172\n",
      "Total training time: 26.05 seconds.\n",
      "-- Epoch 97\n",
      "Norm: 1696.95, NNZs: 3072, Bias: -152.778720, T: 4850000, Avg. loss: 9098.272884\n",
      "Total training time: 26.31 seconds.\n",
      "-- Epoch 98\n",
      "Norm: 1687.45, NNZs: 3072, Bias: -152.930551, T: 4900000, Avg. loss: 8914.886078\n",
      "Total training time: 26.57 seconds.\n",
      "-- Epoch 99\n",
      "Norm: 1678.24, NNZs: 3072, Bias: -153.068470, T: 4950000, Avg. loss: 8808.251443\n",
      "Total training time: 26.83 seconds.\n",
      "-- Epoch 100\n",
      "Norm: 1668.70, NNZs: 3072, Bias: -153.255474, T: 5000000, Avg. loss: 8772.608402\n",
      "Total training time: 27.11 seconds.\n",
      "-- Epoch 101\n",
      "Norm: 1663.15, NNZs: 3072, Bias: -153.438567, T: 5050000, Avg. loss: 8550.444017\n",
      "Total training time: 27.38 seconds.\n",
      "-- Epoch 102\n",
      "Norm: 1653.29, NNZs: 3072, Bias: -153.623791, T: 5100000, Avg. loss: 8537.462866\n",
      "Total training time: 27.63 seconds.\n",
      "-- Epoch 103\n",
      "Norm: 1646.35, NNZs: 3072, Bias: -153.787563, T: 5150000, Avg. loss: 8469.308690\n",
      "Total training time: 27.88 seconds.\n",
      "-- Epoch 104\n",
      "Norm: 1638.39, NNZs: 3072, Bias: -153.951915, T: 5200000, Avg. loss: 8389.629000\n",
      "Total training time: 28.14 seconds.\n",
      "-- Epoch 105\n",
      "Norm: 1630.23, NNZs: 3072, Bias: -154.097220, T: 5250000, Avg. loss: 8342.588603\n",
      "Total training time: 28.38 seconds.\n",
      "-- Epoch 106\n",
      "Norm: 1623.85, NNZs: 3072, Bias: -154.237391, T: 5300000, Avg. loss: 8270.340582\n",
      "Total training time: 28.62 seconds.\n",
      "-- Epoch 107\n",
      "Norm: 1618.01, NNZs: 3072, Bias: -154.415790, T: 5350000, Avg. loss: 8172.432604\n",
      "Total training time: 28.87 seconds.\n",
      "-- Epoch 108\n",
      "Norm: 1609.62, NNZs: 3072, Bias: -154.540364, T: 5400000, Avg. loss: 8144.258382\n",
      "Total training time: 29.13 seconds.\n",
      "-- Epoch 109\n",
      "Norm: 1599.98, NNZs: 3072, Bias: -154.623270, T: 5450000, Avg. loss: 8012.497646\n",
      "Total training time: 29.40 seconds.\n",
      "-- Epoch 110\n",
      "Norm: 1594.88, NNZs: 3072, Bias: -154.767639, T: 5500000, Avg. loss: 7884.604686\n",
      "Total training time: 29.65 seconds.\n",
      "-- Epoch 111\n",
      "Norm: 1586.92, NNZs: 3072, Bias: -154.921241, T: 5550000, Avg. loss: 7954.244986\n",
      "Total training time: 29.92 seconds.\n",
      "-- Epoch 112\n",
      "Norm: 1577.41, NNZs: 3072, Bias: -155.077335, T: 5600000, Avg. loss: 7745.693945\n",
      "Total training time: 30.19 seconds.\n",
      "-- Epoch 113\n",
      "Norm: 1572.23, NNZs: 3072, Bias: -155.169664, T: 5650000, Avg. loss: 7737.202146\n",
      "Total training time: 30.46 seconds.\n",
      "-- Epoch 114\n",
      "Norm: 1566.20, NNZs: 3072, Bias: -155.275567, T: 5700000, Avg. loss: 7613.747522\n",
      "Total training time: 30.71 seconds.\n",
      "-- Epoch 115\n",
      "Norm: 1560.12, NNZs: 3072, Bias: -155.396120, T: 5750000, Avg. loss: 7603.937067\n",
      "Total training time: 30.97 seconds.\n",
      "-- Epoch 116\n",
      "Norm: 1552.38, NNZs: 3072, Bias: -155.541617, T: 5800000, Avg. loss: 7548.526157\n",
      "Total training time: 31.23 seconds.\n",
      "-- Epoch 117\n",
      "Norm: 1545.88, NNZs: 3072, Bias: -155.718451, T: 5850000, Avg. loss: 7437.203056\n",
      "Total training time: 31.47 seconds.\n",
      "-- Epoch 118\n",
      "Norm: 1539.03, NNZs: 3072, Bias: -155.893705, T: 5900000, Avg. loss: 7358.040144\n",
      "Total training time: 31.70 seconds.\n",
      "-- Epoch 119\n",
      "Norm: 1533.19, NNZs: 3072, Bias: -156.055702, T: 5950000, Avg. loss: 7372.550519\n",
      "Total training time: 31.96 seconds.\n",
      "-- Epoch 120\n",
      "Norm: 1527.37, NNZs: 3072, Bias: -156.204594, T: 6000000, Avg. loss: 7305.009717\n",
      "Total training time: 32.21 seconds.\n",
      "-- Epoch 121\n",
      "Norm: 1521.06, NNZs: 3072, Bias: -156.314165, T: 6050000, Avg. loss: 7185.658700\n",
      "Total training time: 32.45 seconds.\n",
      "-- Epoch 122\n",
      "Norm: 1513.34, NNZs: 3072, Bias: -156.422700, T: 6100000, Avg. loss: 7121.429387\n",
      "Total training time: 32.68 seconds.\n",
      "-- Epoch 123\n",
      "Norm: 1506.61, NNZs: 3072, Bias: -156.509336, T: 6150000, Avg. loss: 7043.214913\n",
      "Total training time: 32.94 seconds.\n",
      "-- Epoch 124\n",
      "Norm: 1501.79, NNZs: 3072, Bias: -156.627669, T: 6200000, Avg. loss: 6976.920350\n",
      "Total training time: 33.19 seconds.\n",
      "-- Epoch 125\n",
      "Norm: 1496.14, NNZs: 3072, Bias: -156.773876, T: 6250000, Avg. loss: 6963.191201\n",
      "Total training time: 33.42 seconds.\n",
      "-- Epoch 126\n",
      "Norm: 1488.18, NNZs: 3072, Bias: -156.915730, T: 6300000, Avg. loss: 6923.790312\n",
      "Total training time: 33.66 seconds.\n",
      "-- Epoch 127\n",
      "Norm: 1482.92, NNZs: 3072, Bias: -157.020124, T: 6350000, Avg. loss: 6852.340839\n",
      "Total training time: 33.90 seconds.\n",
      "-- Epoch 128\n",
      "Norm: 1476.86, NNZs: 3072, Bias: -157.106393, T: 6400000, Avg. loss: 6839.825621\n",
      "Total training time: 34.16 seconds.\n",
      "-- Epoch 129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 1471.61, NNZs: 3072, Bias: -157.260359, T: 6450000, Avg. loss: 6724.311886\n",
      "Total training time: 34.40 seconds.\n",
      "-- Epoch 130\n",
      "Norm: 1465.43, NNZs: 3072, Bias: -157.345411, T: 6500000, Avg. loss: 6732.226382\n",
      "Total training time: 34.65 seconds.\n",
      "-- Epoch 131\n",
      "Norm: 1458.70, NNZs: 3072, Bias: -157.458784, T: 6550000, Avg. loss: 6611.878505\n",
      "Total training time: 34.93 seconds.\n",
      "-- Epoch 132\n",
      "Norm: 1453.07, NNZs: 3072, Bias: -157.547037, T: 6600000, Avg. loss: 6498.540392\n",
      "Total training time: 35.22 seconds.\n",
      "-- Epoch 133\n",
      "Norm: 1449.55, NNZs: 3072, Bias: -157.651317, T: 6650000, Avg. loss: 6523.208906\n",
      "Total training time: 35.48 seconds.\n",
      "-- Epoch 134\n",
      "Norm: 1443.30, NNZs: 3072, Bias: -157.798226, T: 6700000, Avg. loss: 6462.509270\n",
      "Total training time: 35.73 seconds.\n",
      "-- Epoch 135\n",
      "Norm: 1436.84, NNZs: 3072, Bias: -157.933598, T: 6750000, Avg. loss: 6428.483691\n",
      "Total training time: 35.98 seconds.\n",
      "-- Epoch 136\n",
      "Norm: 1431.58, NNZs: 3072, Bias: -158.044279, T: 6800000, Avg. loss: 6421.856553\n",
      "Total training time: 36.24 seconds.\n",
      "-- Epoch 137\n",
      "Norm: 1426.83, NNZs: 3072, Bias: -158.162868, T: 6850000, Avg. loss: 6362.876940\n",
      "Total training time: 36.48 seconds.\n",
      "-- Epoch 138\n",
      "Norm: 1420.70, NNZs: 3072, Bias: -158.305343, T: 6900000, Avg. loss: 6318.512700\n",
      "Total training time: 36.71 seconds.\n",
      "-- Epoch 139\n",
      "Norm: 1416.55, NNZs: 3072, Bias: -158.446867, T: 6950000, Avg. loss: 6262.174487\n",
      "Total training time: 36.95 seconds.\n",
      "-- Epoch 140\n",
      "Norm: 1411.46, NNZs: 3072, Bias: -158.511374, T: 7000000, Avg. loss: 6136.324285\n",
      "Total training time: 37.20 seconds.\n",
      "-- Epoch 141\n",
      "Norm: 1406.83, NNZs: 3072, Bias: -158.623959, T: 7050000, Avg. loss: 6215.196235\n",
      "Total training time: 37.44 seconds.\n",
      "-- Epoch 142\n",
      "Norm: 1403.90, NNZs: 3072, Bias: -158.749751, T: 7100000, Avg. loss: 6160.452452\n",
      "Total training time: 37.68 seconds.\n",
      "-- Epoch 143\n",
      "Norm: 1398.96, NNZs: 3072, Bias: -158.889983, T: 7150000, Avg. loss: 6011.375451\n",
      "Total training time: 37.92 seconds.\n",
      "-- Epoch 144\n",
      "Norm: 1392.93, NNZs: 3072, Bias: -159.011227, T: 7200000, Avg. loss: 6017.567360\n",
      "Total training time: 38.17 seconds.\n",
      "-- Epoch 145\n",
      "Norm: 1389.30, NNZs: 3072, Bias: -159.149583, T: 7250000, Avg. loss: 5997.746955\n",
      "Total training time: 38.41 seconds.\n",
      "-- Epoch 146\n",
      "Norm: 1384.47, NNZs: 3072, Bias: -159.278758, T: 7300000, Avg. loss: 5941.960648\n",
      "Total training time: 38.65 seconds.\n",
      "-- Epoch 147\n",
      "Norm: 1379.42, NNZs: 3072, Bias: -159.364701, T: 7350000, Avg. loss: 5908.444763\n",
      "Total training time: 38.88 seconds.\n",
      "-- Epoch 148\n",
      "Norm: 1374.83, NNZs: 3072, Bias: -159.483975, T: 7400000, Avg. loss: 5801.922949\n",
      "Total training time: 39.13 seconds.\n",
      "-- Epoch 149\n",
      "Norm: 1368.61, NNZs: 3072, Bias: -159.562146, T: 7450000, Avg. loss: 5796.505740\n",
      "Total training time: 39.37 seconds.\n",
      "-- Epoch 150\n",
      "Norm: 1364.01, NNZs: 3072, Bias: -159.639767, T: 7500000, Avg. loss: 5775.196911\n",
      "Total training time: 39.61 seconds.\n",
      "-- Epoch 151\n",
      "Norm: 1360.75, NNZs: 3072, Bias: -159.716876, T: 7550000, Avg. loss: 5784.707329\n",
      "Total training time: 39.84 seconds.\n",
      "-- Epoch 152\n",
      "Norm: 1356.23, NNZs: 3072, Bias: -159.839590, T: 7600000, Avg. loss: 5737.131479\n",
      "Total training time: 40.10 seconds.\n",
      "-- Epoch 153\n",
      "Norm: 1352.39, NNZs: 3072, Bias: -159.932664, T: 7650000, Avg. loss: 5639.016255\n",
      "Total training time: 40.34 seconds.\n",
      "-- Epoch 154\n",
      "Norm: 1349.09, NNZs: 3072, Bias: -160.014833, T: 7700000, Avg. loss: 5661.038039\n",
      "Total training time: 40.58 seconds.\n",
      "-- Epoch 155\n",
      "Norm: 1344.81, NNZs: 3072, Bias: -160.132628, T: 7750000, Avg. loss: 5644.854591\n",
      "Total training time: 40.81 seconds.\n",
      "-- Epoch 156\n",
      "Norm: 1340.01, NNZs: 3072, Bias: -160.234255, T: 7800000, Avg. loss: 5558.247370\n",
      "Total training time: 41.06 seconds.\n",
      "-- Epoch 157\n",
      "Norm: 1337.16, NNZs: 3072, Bias: -160.327553, T: 7850000, Avg. loss: 5518.557895\n",
      "Total training time: 41.31 seconds.\n",
      "-- Epoch 158\n",
      "Norm: 1332.31, NNZs: 3072, Bias: -160.441800, T: 7900000, Avg. loss: 5480.426555\n",
      "Total training time: 41.54 seconds.\n",
      "-- Epoch 159\n",
      "Norm: 1328.90, NNZs: 3072, Bias: -160.576798, T: 7950000, Avg. loss: 5402.295351\n",
      "Total training time: 41.78 seconds.\n",
      "-- Epoch 160\n",
      "Norm: 1324.08, NNZs: 3072, Bias: -160.698377, T: 8000000, Avg. loss: 5416.119298\n",
      "Total training time: 42.03 seconds.\n",
      "-- Epoch 161\n",
      "Norm: 1320.14, NNZs: 3072, Bias: -160.776885, T: 8050000, Avg. loss: 5366.647420\n",
      "Total training time: 42.27 seconds.\n",
      "-- Epoch 162\n",
      "Norm: 1314.62, NNZs: 3072, Bias: -160.885877, T: 8100000, Avg. loss: 5385.067415\n",
      "Total training time: 42.52 seconds.\n",
      "-- Epoch 163\n",
      "Norm: 1310.80, NNZs: 3072, Bias: -160.980643, T: 8150000, Avg. loss: 5287.754911\n",
      "Total training time: 42.76 seconds.\n",
      "-- Epoch 164\n",
      "Norm: 1307.21, NNZs: 3072, Bias: -161.057677, T: 8200000, Avg. loss: 5294.146212\n",
      "Total training time: 43.01 seconds.\n",
      "-- Epoch 165\n",
      "Norm: 1302.90, NNZs: 3072, Bias: -161.182875, T: 8250000, Avg. loss: 5218.133780\n",
      "Total training time: 43.25 seconds.\n",
      "-- Epoch 166\n",
      "Norm: 1298.35, NNZs: 3072, Bias: -161.267504, T: 8300000, Avg. loss: 5197.538662\n",
      "Total training time: 43.49 seconds.\n",
      "-- Epoch 167\n",
      "Norm: 1294.59, NNZs: 3072, Bias: -161.332390, T: 8350000, Avg. loss: 5210.820670\n",
      "Total training time: 43.73 seconds.\n",
      "-- Epoch 168\n",
      "Norm: 1290.92, NNZs: 3072, Bias: -161.421929, T: 8400000, Avg. loss: 5175.824677\n",
      "Total training time: 43.99 seconds.\n",
      "-- Epoch 169\n",
      "Norm: 1288.42, NNZs: 3072, Bias: -161.509785, T: 8450000, Avg. loss: 5138.344985\n",
      "Total training time: 44.27 seconds.\n",
      "-- Epoch 170\n",
      "Norm: 1283.98, NNZs: 3072, Bias: -161.588872, T: 8500000, Avg. loss: 5065.634751\n",
      "Total training time: 44.52 seconds.\n",
      "-- Epoch 171\n",
      "Norm: 1281.17, NNZs: 3072, Bias: -161.686369, T: 8550000, Avg. loss: 5065.965930\n",
      "Total training time: 44.77 seconds.\n",
      "-- Epoch 172\n",
      "Norm: 1276.37, NNZs: 3072, Bias: -161.806464, T: 8600000, Avg. loss: 5028.958299\n",
      "Total training time: 45.03 seconds.\n",
      "-- Epoch 173\n",
      "Norm: 1273.18, NNZs: 3072, Bias: -161.899215, T: 8650000, Avg. loss: 4995.268778\n",
      "Total training time: 45.29 seconds.\n",
      "-- Epoch 174\n",
      "Norm: 1269.39, NNZs: 3072, Bias: -162.008712, T: 8700000, Avg. loss: 4923.703576\n",
      "Total training time: 45.54 seconds.\n",
      "-- Epoch 175\n",
      "Norm: 1265.78, NNZs: 3072, Bias: -162.087784, T: 8750000, Avg. loss: 4886.027538\n",
      "Total training time: 45.79 seconds.\n",
      "-- Epoch 176\n",
      "Norm: 1262.31, NNZs: 3072, Bias: -162.197172, T: 8800000, Avg. loss: 4972.194616\n",
      "Total training time: 46.05 seconds.\n",
      "-- Epoch 177\n",
      "Norm: 1259.08, NNZs: 3072, Bias: -162.299169, T: 8850000, Avg. loss: 4865.490070\n",
      "Total training time: 46.31 seconds.\n",
      "-- Epoch 178\n",
      "Norm: 1255.77, NNZs: 3072, Bias: -162.416366, T: 8900000, Avg. loss: 4879.028458\n",
      "Total training time: 46.57 seconds.\n",
      "-- Epoch 179\n",
      "Norm: 1252.38, NNZs: 3072, Bias: -162.518337, T: 8950000, Avg. loss: 4764.667543\n",
      "Total training time: 46.83 seconds.\n",
      "-- Epoch 180\n",
      "Norm: 1248.60, NNZs: 3072, Bias: -162.599630, T: 9000000, Avg. loss: 4793.151187\n",
      "Total training time: 47.11 seconds.\n",
      "-- Epoch 181\n",
      "Norm: 1245.23, NNZs: 3072, Bias: -162.681572, T: 9050000, Avg. loss: 4757.903666\n",
      "Total training time: 47.37 seconds.\n",
      "-- Epoch 182\n",
      "Norm: 1241.63, NNZs: 3072, Bias: -162.776322, T: 9100000, Avg. loss: 4721.364544\n",
      "Total training time: 47.63 seconds.\n",
      "-- Epoch 183\n",
      "Norm: 1237.78, NNZs: 3072, Bias: -162.855200, T: 9150000, Avg. loss: 4758.153605\n",
      "Total training time: 47.90 seconds.\n",
      "-- Epoch 184\n",
      "Norm: 1234.34, NNZs: 3072, Bias: -162.938025, T: 9200000, Avg. loss: 4718.103654\n",
      "Total training time: 48.18 seconds.\n",
      "-- Epoch 185\n",
      "Norm: 1230.53, NNZs: 3072, Bias: -163.026919, T: 9250000, Avg. loss: 4712.733113\n",
      "Total training time: 48.43 seconds.\n",
      "-- Epoch 186\n",
      "Norm: 1227.68, NNZs: 3072, Bias: -163.114296, T: 9300000, Avg. loss: 4680.310083\n",
      "Total training time: 48.69 seconds.\n",
      "-- Epoch 187\n",
      "Norm: 1225.30, NNZs: 3072, Bias: -163.193668, T: 9350000, Avg. loss: 4597.297882\n",
      "Total training time: 48.95 seconds.\n",
      "-- Epoch 188\n",
      "Norm: 1221.73, NNZs: 3072, Bias: -163.295001, T: 9400000, Avg. loss: 4626.509924\n",
      "Total training time: 49.21 seconds.\n",
      "-- Epoch 189\n",
      "Norm: 1218.12, NNZs: 3072, Bias: -163.391491, T: 9450000, Avg. loss: 4597.971838\n",
      "Total training time: 49.46 seconds.\n",
      "-- Epoch 190\n",
      "Norm: 1215.24, NNZs: 3072, Bias: -163.502299, T: 9500000, Avg. loss: 4562.814826\n",
      "Total training time: 49.70 seconds.\n",
      "-- Epoch 191\n",
      "Norm: 1211.66, NNZs: 3072, Bias: -163.605209, T: 9550000, Avg. loss: 4532.817417\n",
      "Total training time: 49.96 seconds.\n",
      "-- Epoch 192\n",
      "Norm: 1209.76, NNZs: 3072, Bias: -163.676229, T: 9600000, Avg. loss: 4542.523636\n",
      "Total training time: 50.21 seconds.\n",
      "-- Epoch 193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 1205.83, NNZs: 3072, Bias: -163.749996, T: 9650000, Avg. loss: 4476.025650\n",
      "Total training time: 50.45 seconds.\n",
      "-- Epoch 194\n",
      "Norm: 1203.34, NNZs: 3072, Bias: -163.788259, T: 9700000, Avg. loss: 4422.087237\n",
      "Total training time: 50.68 seconds.\n",
      "-- Epoch 195\n",
      "Norm: 1200.38, NNZs: 3072, Bias: -163.877735, T: 9750000, Avg. loss: 4464.565348\n",
      "Total training time: 50.93 seconds.\n",
      "-- Epoch 196\n",
      "Norm: 1197.57, NNZs: 3072, Bias: -163.963643, T: 9800000, Avg. loss: 4423.708445\n",
      "Total training time: 51.19 seconds.\n",
      "-- Epoch 197\n",
      "Norm: 1194.73, NNZs: 3072, Bias: -164.062372, T: 9850000, Avg. loss: 4383.673006\n",
      "Total training time: 51.43 seconds.\n",
      "-- Epoch 198\n",
      "Norm: 1192.66, NNZs: 3072, Bias: -164.146384, T: 9900000, Avg. loss: 4368.038562\n",
      "Total training time: 51.68 seconds.\n",
      "-- Epoch 199\n",
      "Norm: 1188.15, NNZs: 3072, Bias: -164.219893, T: 9950000, Avg. loss: 4313.740029\n",
      "Total training time: 51.94 seconds.\n",
      "-- Epoch 200\n",
      "Norm: 1185.42, NNZs: 3072, Bias: -164.293040, T: 10000000, Avg. loss: 4296.716362\n",
      "Total training time: 52.20 seconds.\n",
      "-- Epoch 201\n",
      "Norm: 1183.18, NNZs: 3072, Bias: -164.364881, T: 10050000, Avg. loss: 4302.852687\n",
      "Total training time: 52.45 seconds.\n",
      "-- Epoch 202\n",
      "Norm: 1179.78, NNZs: 3072, Bias: -164.437366, T: 10100000, Avg. loss: 4299.039421\n",
      "Total training time: 52.70 seconds.\n",
      "-- Epoch 203\n",
      "Norm: 1177.99, NNZs: 3072, Bias: -164.489661, T: 10150000, Avg. loss: 4265.147990\n",
      "Total training time: 52.96 seconds.\n",
      "-- Epoch 204\n",
      "Norm: 1174.95, NNZs: 3072, Bias: -164.544677, T: 10200000, Avg. loss: 4268.974601\n",
      "Total training time: 53.23 seconds.\n",
      "-- Epoch 205\n",
      "Norm: 1172.41, NNZs: 3072, Bias: -164.603361, T: 10250000, Avg. loss: 4196.452126\n",
      "Total training time: 53.48 seconds.\n",
      "-- Epoch 206\n",
      "Norm: 1169.85, NNZs: 3072, Bias: -164.690938, T: 10300000, Avg. loss: 4186.962398\n",
      "Total training time: 53.72 seconds.\n",
      "-- Epoch 207\n",
      "Norm: 1167.31, NNZs: 3072, Bias: -164.752919, T: 10350000, Avg. loss: 4185.318960\n",
      "Total training time: 53.97 seconds.\n",
      "-- Epoch 208\n",
      "Norm: 1164.15, NNZs: 3072, Bias: -164.836774, T: 10400000, Avg. loss: 4133.406009\n",
      "Total training time: 54.23 seconds.\n",
      "-- Epoch 209\n",
      "Norm: 1160.85, NNZs: 3072, Bias: -164.891451, T: 10450000, Avg. loss: 4136.233769\n",
      "Total training time: 54.48 seconds.\n",
      "-- Epoch 210\n",
      "Norm: 1158.28, NNZs: 3072, Bias: -164.973513, T: 10500000, Avg. loss: 4131.954663\n",
      "Total training time: 54.72 seconds.\n",
      "-- Epoch 211\n",
      "Norm: 1155.64, NNZs: 3072, Bias: -165.032457, T: 10550000, Avg. loss: 4064.069378\n",
      "Total training time: 54.97 seconds.\n",
      "-- Epoch 212\n",
      "Norm: 1153.14, NNZs: 3072, Bias: -165.097688, T: 10600000, Avg. loss: 4069.102309\n",
      "Total training time: 55.24 seconds.\n",
      "-- Epoch 213\n",
      "Norm: 1150.09, NNZs: 3072, Bias: -165.169201, T: 10650000, Avg. loss: 4046.612033\n",
      "Total training time: 55.48 seconds.\n",
      "-- Epoch 214\n",
      "Norm: 1147.63, NNZs: 3072, Bias: -165.226319, T: 10700000, Avg. loss: 4010.703703\n",
      "Total training time: 55.72 seconds.\n",
      "-- Epoch 215\n",
      "Norm: 1144.37, NNZs: 3072, Bias: -165.284049, T: 10750000, Avg. loss: 4053.944363\n",
      "Total training time: 55.96 seconds.\n",
      "-- Epoch 216\n",
      "Norm: 1141.20, NNZs: 3072, Bias: -165.340651, T: 10800000, Avg. loss: 4049.118766\n",
      "Total training time: 56.22 seconds.\n",
      "-- Epoch 217\n",
      "Norm: 1138.11, NNZs: 3072, Bias: -165.390530, T: 10850000, Avg. loss: 4006.936478\n",
      "Total training time: 56.46 seconds.\n",
      "-- Epoch 218\n",
      "Norm: 1136.15, NNZs: 3072, Bias: -165.453040, T: 10900000, Avg. loss: 3961.633387\n",
      "Total training time: 56.69 seconds.\n",
      "-- Epoch 219\n",
      "Norm: 1133.16, NNZs: 3072, Bias: -165.507034, T: 10950000, Avg. loss: 3918.969451\n",
      "Total training time: 56.93 seconds.\n",
      "-- Epoch 220\n",
      "Norm: 1130.09, NNZs: 3072, Bias: -165.567172, T: 11000000, Avg. loss: 3944.003569\n",
      "Total training time: 57.18 seconds.\n",
      "-- Epoch 221\n",
      "Norm: 1127.10, NNZs: 3072, Bias: -165.628792, T: 11050000, Avg. loss: 3884.044490\n",
      "Total training time: 57.42 seconds.\n",
      "-- Epoch 222\n",
      "Norm: 1123.60, NNZs: 3072, Bias: -165.674897, T: 11100000, Avg. loss: 3861.226615\n",
      "Total training time: 57.66 seconds.\n",
      "-- Epoch 223\n",
      "Norm: 1121.93, NNZs: 3072, Bias: -165.751311, T: 11150000, Avg. loss: 3916.402041\n",
      "Total training time: 57.89 seconds.\n",
      "-- Epoch 224\n",
      "Norm: 1119.05, NNZs: 3072, Bias: -165.841672, T: 11200000, Avg. loss: 3859.930468\n",
      "Total training time: 58.16 seconds.\n",
      "-- Epoch 225\n",
      "Norm: 1116.79, NNZs: 3072, Bias: -165.902245, T: 11250000, Avg. loss: 3863.379877\n",
      "Total training time: 58.41 seconds.\n",
      "-- Epoch 226\n",
      "Norm: 1113.92, NNZs: 3072, Bias: -165.974950, T: 11300000, Avg. loss: 3831.845575\n",
      "Total training time: 58.66 seconds.\n",
      "-- Epoch 227\n",
      "Norm: 1111.34, NNZs: 3072, Bias: -166.064126, T: 11350000, Avg. loss: 3787.027583\n",
      "Total training time: 58.92 seconds.\n",
      "-- Epoch 228\n",
      "Norm: 1109.68, NNZs: 3072, Bias: -166.129157, T: 11400000, Avg. loss: 3800.012309\n",
      "Total training time: 59.20 seconds.\n",
      "-- Epoch 229\n",
      "Norm: 1107.32, NNZs: 3072, Bias: -166.225464, T: 11450000, Avg. loss: 3776.727110\n",
      "Total training time: 59.45 seconds.\n",
      "-- Epoch 230\n",
      "Norm: 1105.43, NNZs: 3072, Bias: -166.280362, T: 11500000, Avg. loss: 3728.232938\n",
      "Total training time: 59.70 seconds.\n",
      "-- Epoch 231\n",
      "Norm: 1102.70, NNZs: 3072, Bias: -166.335084, T: 11550000, Avg. loss: 3756.441396\n",
      "Total training time: 59.95 seconds.\n",
      "-- Epoch 232\n",
      "Norm: 1100.02, NNZs: 3072, Bias: -166.420599, T: 11600000, Avg. loss: 3737.748743\n",
      "Total training time: 60.22 seconds.\n",
      "-- Epoch 233\n",
      "Norm: 1097.35, NNZs: 3072, Bias: -166.499720, T: 11650000, Avg. loss: 3699.243271\n",
      "Total training time: 60.48 seconds.\n",
      "-- Epoch 234\n",
      "Norm: 1095.23, NNZs: 3072, Bias: -166.564829, T: 11700000, Avg. loss: 3687.477501\n",
      "Total training time: 60.73 seconds.\n",
      "-- Epoch 235\n",
      "Norm: 1092.08, NNZs: 3072, Bias: -166.625346, T: 11750000, Avg. loss: 3663.409519\n",
      "Total training time: 60.97 seconds.\n",
      "-- Epoch 236\n",
      "Norm: 1089.63, NNZs: 3072, Bias: -166.701733, T: 11800000, Avg. loss: 3651.266050\n",
      "Total training time: 61.23 seconds.\n",
      "-- Epoch 237\n",
      "Norm: 1087.64, NNZs: 3072, Bias: -166.767721, T: 11850000, Avg. loss: 3613.679070\n",
      "Total training time: 61.49 seconds.\n",
      "-- Epoch 238\n",
      "Norm: 1085.70, NNZs: 3072, Bias: -166.839277, T: 11900000, Avg. loss: 3616.923601\n",
      "Total training time: 61.74 seconds.\n",
      "-- Epoch 239\n",
      "Norm: 1083.37, NNZs: 3072, Bias: -166.898866, T: 11950000, Avg. loss: 3615.979271\n",
      "Total training time: 61.99 seconds.\n",
      "-- Epoch 240\n",
      "Norm: 1080.92, NNZs: 3072, Bias: -166.989896, T: 12000000, Avg. loss: 3632.434247\n",
      "Total training time: 62.26 seconds.\n",
      "-- Epoch 241\n",
      "Norm: 1078.86, NNZs: 3072, Bias: -167.051442, T: 12050000, Avg. loss: 3558.614086\n",
      "Total training time: 62.51 seconds.\n",
      "-- Epoch 242\n",
      "Norm: 1077.34, NNZs: 3072, Bias: -167.120980, T: 12100000, Avg. loss: 3550.599315\n",
      "Total training time: 62.76 seconds.\n",
      "-- Epoch 243\n",
      "Norm: 1074.86, NNZs: 3072, Bias: -167.164707, T: 12150000, Avg. loss: 3575.294396\n",
      "Total training time: 63.02 seconds.\n",
      "-- Epoch 244\n",
      "Norm: 1072.86, NNZs: 3072, Bias: -167.240281, T: 12200000, Avg. loss: 3509.131009\n",
      "Total training time: 63.29 seconds.\n",
      "-- Epoch 245\n",
      "Norm: 1070.98, NNZs: 3072, Bias: -167.307334, T: 12250000, Avg. loss: 3488.451531\n",
      "Total training time: 63.55 seconds.\n",
      "-- Epoch 246\n",
      "Norm: 1068.61, NNZs: 3072, Bias: -167.382264, T: 12300000, Avg. loss: 3512.962153\n",
      "Total training time: 63.80 seconds.\n",
      "-- Epoch 247\n",
      "Norm: 1067.10, NNZs: 3072, Bias: -167.463443, T: 12350000, Avg. loss: 3460.938651\n",
      "Total training time: 64.07 seconds.\n",
      "-- Epoch 248\n",
      "Norm: 1064.49, NNZs: 3072, Bias: -167.531295, T: 12400000, Avg. loss: 3458.143182\n",
      "Total training time: 64.34 seconds.\n",
      "-- Epoch 249\n",
      "Norm: 1062.18, NNZs: 3072, Bias: -167.598064, T: 12450000, Avg. loss: 3443.687645\n",
      "Total training time: 64.60 seconds.\n",
      "-- Epoch 250\n",
      "Norm: 1059.86, NNZs: 3072, Bias: -167.669438, T: 12500000, Avg. loss: 3469.775980\n",
      "Total training time: 64.85 seconds.\n",
      "-- Epoch 251\n",
      "Norm: 1057.65, NNZs: 3072, Bias: -167.706165, T: 12550000, Avg. loss: 3469.783203\n",
      "Total training time: 65.11 seconds.\n",
      "-- Epoch 252\n",
      "Norm: 1056.28, NNZs: 3072, Bias: -167.780910, T: 12600000, Avg. loss: 3386.552891\n",
      "Total training time: 65.38 seconds.\n",
      "-- Epoch 253\n",
      "Norm: 1053.74, NNZs: 3072, Bias: -167.841128, T: 12650000, Avg. loss: 3403.619360\n",
      "Total training time: 65.64 seconds.\n",
      "-- Epoch 254\n",
      "Norm: 1052.00, NNZs: 3072, Bias: -167.886082, T: 12700000, Avg. loss: 3386.898796\n",
      "Total training time: 65.89 seconds.\n",
      "-- Epoch 255\n",
      "Norm: 1049.15, NNZs: 3072, Bias: -167.930864, T: 12750000, Avg. loss: 3370.365033\n",
      "Total training time: 66.15 seconds.\n",
      "-- Epoch 256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 1047.13, NNZs: 3072, Bias: -167.981691, T: 12800000, Avg. loss: 3390.233172\n",
      "Total training time: 66.40 seconds.\n",
      "-- Epoch 257\n"
     ]
    }
   ],
   "source": [
    "svm,svmScore = buildmodel('svm',X,Ycatdog,x_test,y_test_catdog,verbose=True)\n",
    "print(\"Linear SVM score :%\",round(svmScore,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling and Evaluation 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We will assess how well each model performs (use 80/20 training/testing split)and adjust parameters of the models to make them more accurate. \n",
    "\n",
    "\n",
    "\"Choose the method you will use for dividing your data into training and\n",
    "testing splits (i.e., are you using Stratified 10-fold cross validation? Why?). Explain why\n",
    "your chosen method is appropriate or use more than one method as appropriate. For example, if you are using time series data then you should be using continuous training and testing sets across time.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling and Evaluation 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We identified the two tasks from the dataset to classify. For each task we will create three different classification/regression models\n",
    "\n",
    "Task 1: Cats and dogs\n",
    "\n",
    "    Model A: Random Forest\n",
    "    Model B: KNN\n",
    "    Model C: Logistic regression\n",
    "    \n",
    "Task 2: Birds and airplanes\n",
    "\n",
    "    Model A: Naive Bayes\n",
    "    Model B: Decision Tree\n",
    "    Model C: SVM\n",
    "    \n",
    "\"Create three different classication/regression models (e.g., random forest, KNN, and SVM). Two modeling techniques must be new (but the third could be SVM or logistic regression). Adjust parameters as appropriate to increase generalization performance using your chosen metric\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task1 Model A\n",
    "(Cats and Dogs- Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task1 Model B\n",
    "(Cats and Dogs- KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task1 Model C\n",
    "(Cats and Dogs- Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task2 Model A\n",
    "(Birds and Airplanes- Naive Bayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task2 Model B\n",
    "(Birds and Airplanes- Decision Tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task2 Model C\n",
    "(Birds and Airplanes- SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling and Evaluation 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Analyze the results using your chosen method of evaluation. Use visualizations of the results to bolster the analysis. Explain any visuals and analyze why they are interesting to someone that might use this model.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling and Evaluation 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Advantages of Task 1: Cats and dogs Model A: Random Forest\n",
    "\n",
    "    *\n",
    "Advantages of Task 1: Cats and dogsModel B: KNN\n",
    "\n",
    "    *\n",
    "Advantages of Task 1: Cats and dogsModel C: Logistic regression\n",
    "\n",
    "    *\n",
    "Advantages of Task 2: Birds and airplanes Model A: Naive Bayes\n",
    "\n",
    "    *\n",
    "Advantages of Task 2: Birds and airplanes Model B: Decision Tree\n",
    "\n",
    "    *\n",
    "Advantages of Task 2: Birds and airplanes Model C: SVM\n",
    "\n",
    "    *\n",
    "\n",
    "\"Discuss the advantages of each model for each classification task, if any. If there are not advantages, explain why. Is any model better than another? Is the difference significant with 95% confidence? Use proper statistical comparison methods. You must use statistical comparison techniquesbe sure they are appropriate for your chosen method of validation as discussed in unit 7 of the course.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling and Evaluation 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The attributes from our analysis that are most imortant are\n",
    "\n",
    "\"Which attributes from your analysis are most important? Use proper methods discussed in class to evaluate the importance of different attributes. Discuss the results and hypothesize about why certain attributes are more important than others for a given classification task.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We believe that our model would be best suited for\n",
    "\n",
    "\"How useful is your model for interested parties (i.e., the companies or organizations that might want to use it for prediction)? How would you measure the model's value if it was used by these parties? How would your deploy your model for interested parties? What other data should be collected? How often would the model need to be updated, etc.?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLD- MAY DELETE -Create Models\n",
    "\n",
    "In this section we will create a logistic regression model and a support vector machine model for the classification task involved with your dataset.  We will assess how well each model performs (use 80/20 training/testing split)and adjust parameters of the models to make them more accurate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of our primary concerns was that single level logistic regression cannot handle a multiclass problem very well.  In order to tackle this issue we decided to change to simplify the problem to a binary classification exercise. We modified the training labels to be either the \"CAT\"/\"NOT CAT\" which simplified the task for our models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLD- MAY DELETE -Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Build Logistic Regression Model with Stochastic Gradient Descent \n",
    "X,Y = load_cfar10_batch(\"data/\",1,False)\n",
    "\n",
    "for n in range(2,6):\n",
    "    x,y = load_cfar10_batch(\"data/\",n,False)    \n",
    "    X = np.concatenate((X,x),axis=0)\n",
    "    Y = np.concatenate((Y,y),axis=0)\n",
    "\n",
    "test_X,test_Y = load_cfar10_batch(\"data/test_batch\",None,False)\n",
    "\n",
    "# Modify the dataset labels to lable cats/not/cats\n",
    "#(if_test_is_false, if_test_is_true)[test]\n",
    "catY = (Y == 3)\n",
    "cat_test_Y = (test_Y == 3) \n",
    "\n",
    "sgdlr = SGDClassifier(alpha=0.001, max_iter=5000, tol=1e-3,verbose=1,n_jobs=4,loss=\"log\")\n",
    "\n",
    "print(\"Data shape: \",X.shape)\n",
    "print(\"Labels shape: \",catY.shape)\n",
    "\n",
    "print(\"Test Data shape: \",test_X.shape)\n",
    "print(\"Test Labels shape: \",cat_test_Y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "sgdlr.fit(X,catY)\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(\"Training complete.  Time elapsed = \",elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgdlrscore = sgdlr.score(test_X,cat_test_Y)\n",
    "print(\"Logistic Regression Accuracy: \",sgdlrscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLD- MAY DELETE -Support Vector Machine Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build SVM Regression Model with Stochastic Gradient Descent \n",
    "sgd_svm = SGDClassifier(alpha=0.001, max_iter=5000, verbose = 1, tol=1e-3,n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "sgd_svm.fit(X,catY)\n",
    "end = time.time()\n",
    "\n",
    "svm_elapsed = end - start\n",
    "print(\"Training complete.  Time elapsed = \",svm_elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_svmscore = sgd_svm.score(test_X,cat_test_Y)\n",
    "print(\"Support Vector Machine Model: \",sgd_svmscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Weights\n",
    "weights = sgd_svm.coef_\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLD- MAY DELETE -Model Advantages\n",
    "\n",
    "We will discuss the advantages of each model for each classification task. Does one type of model offer superior performance over another in terms of prediction accuracy? In terms of training time or efficiency?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def print_mislabeled_images(X, y, p):\n",
    "    \"\"\"\n",
    "    Plots images where predictions and truth were different.\n",
    "    X -- dataset\n",
    "    y -- true labels\n",
    "    p -- predictions\n",
    "    \"\"\"\n",
    "    a = y == p\n",
    "    mislabeled_indices = np.asarray(np.where(a == False))\n",
    "    plt.rcParams['figure.figsize'] = (10.0, 10.0) # set default size of plots\n",
    "    num_images = len(mislabeled_indices[0])\n",
    "    \n",
    "    print(\"There were \"+str(num_images)+\" mislabeled images.\")\n",
    "    print(\"Here is a sampling of 6 of the mislabeled images.\")\n",
    "    \n",
    "    rand_ids = np.random.randint(num_images, size=6)\n",
    "    for i in range(6):\n",
    "        index = mislabeled_indices[0][i]\n",
    "        plt.subplot(3, 2, i + 1)\n",
    "        plt.imshow(X[index].reshape(3, 32, 32).transpose(1,2,0), interpolation='nearest')\n",
    "        plt.axis('off')\n",
    "        plt.title(\"Prediction:\"+str(p[index]) + \"\\nLabel:\"+str(y[index]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  OLD- MAY DELETE -Logistic Regression Mislabeled Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgdpred_test = sgdlr.predict(test_X)\n",
    "print_mislabeled_images(test_X,cat_test_Y,sgdpred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLD- MAY DELETE -Support Vector Machine Mislabeled Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmpred_test = sgd_svm.predict(test_X)\n",
    "print_mislabeled_images(test_X,cat_test_Y,svmpred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLD- MAY DELETE -Model Comparison\n",
    "\n",
    "The two models were trained with similar hyperparameters to simplify the A/B comparison between the two models.  The only parameter that varied between the two models was the *loss* parameter. \n",
    "\n",
    "The loss function defaults to hinge, which gives a linear SVM. The log loss gives logistic regression, a probabilistic classifier. \n",
    "\n",
    "The two models we cerated in identifying cats peformed similarly in terms of accuracy, 85% to 89% accuaracy over several test runs.\n",
    "\n",
    "Training times varied depending on the underlying hardware and computer workload; however, the two models were comparable in overall training times on this dataset 69-72 seconds on Intel Core i7-6700 @ 3.4GHz, 24Gb of RAM, 4 Cores, and and NVIDIA 1060. \n",
    "\n",
    "Both models also seemed to mislabel similar images as evident in the plots above.  Both models seemed to struggle with cats in odd, off center poses, or curled up into a ball.  The one car image that was mislabaled as a cat kind of resemebles a cat with the openned hatchback of the car resembling a tail.\n",
    "\n",
    "Overall both models performed similarily in this classification task with the chosen model parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLD- MAY DELETE -Interpreting Feature Importance\n",
    "\n",
    "In this section we will use the weights from logistic regression to interpret the importance of different features for the classification task.\n",
    "\n",
    "Individual weights represent the strength of connection between our units, in this case it is a connection from our array of pixels which come in three magnitudes of RBG colors. If the weights are overlayed as a matrix we can see the influence of specific colors to help us identify a class. The weights act as a filter coefficient for each pixel of our array of length. We define the score of each class in this case cat vs not cat based on the weighted sum of all the pixels with all images, each class sore is a linear function over this space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Weights\n",
    "print(X.shape)\n",
    "\n",
    "weights = sgd_svm.coef_\n",
    "print(weights.shape)\n",
    "#plt.scatter(X,weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLD- MAY DELETE - Interpreting Support Vectors\n",
    "\n",
    "In this section we will look at the chosen support vectors for the classification task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf = SVC(gamma='auto')\n",
    "clf.fit(X, catY) \n",
    "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
    "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
    "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "    tol=0.001, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
